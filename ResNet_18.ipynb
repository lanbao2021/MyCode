{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无layer和block这种层级关系\n",
    "直接调用torchvision里写好的resnet会参杂很多不必要元素，这对我后续调整网络结构是一个很大的阻碍，这份代码可以让我非常清晰明了的知道ResNet-18的各层细节，没有各种函数调用绕来绕去，当然因为是针对目标检测模型设计的，所以我去掉了最后两层（AvgPool+FC），因为命名方式和层级关系（layer和block）跟PyTorch官方的代码不一样，所以不能使用官方提供的Pre-Training参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "\n",
    "        # ResNet's Head\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet Block-1 \n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # ResNet Block-2 \n",
    "        self.conv6 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.conv7 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.downsample1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                                         nn.BatchNorm2d(128))\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "        self.conv9 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "        self.relu9 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # ResNet Block-3\n",
    "        self.conv10 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn10 = nn.BatchNorm2d(256)\n",
    "        self.relu10 = nn.ReLU(inplace=True)\n",
    "        self.conv11 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.relu11 = nn.ReLU(inplace=True)\n",
    "        self.downsample2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "                                         nn.BatchNorm2d(256))\n",
    "        \n",
    "        self.conv12 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn12 = nn.BatchNorm2d(256)\n",
    "        self.relu12 = nn.ReLU(inplace=True)\n",
    "        self.conv13 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn13 = nn.BatchNorm2d(256)\n",
    "        self.relu13 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # ResNet Block-4\n",
    "        self.conv14 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn14 = nn.BatchNorm2d(512)\n",
    "        self.relu14 = nn.ReLU(inplace=True)\n",
    "        self.conv15 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn15 = nn.BatchNorm2d(512)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "        self.downsample3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "                                         nn.BatchNorm2d(512))\n",
    "        \n",
    "        self.conv16 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn16 = nn.BatchNorm2d(512)\n",
    "        self.relu16 = nn.ReLU(inplace=True)\n",
    "        self.conv17 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn17 = nn.BatchNorm2d(512)\n",
    "        self.relu17 = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.conv1(x)\n",
    "        C1 = self.bn1(C1)\n",
    "        C1 = self.relu1(C1)\n",
    "        C1 = self.maxpool1(C1)\n",
    "\n",
    "        # ResNet Block-1\n",
    "        identity = C1\n",
    "        C2 = self.conv2(C1)\n",
    "        C2 = self.bn2(C2)\n",
    "        C2 = self.relu2(C2)\n",
    "        C3 = self.conv3(C2)\n",
    "        C3 = self.bn3(C3)\n",
    "        C3 = self.relu3(C3 + identity)\n",
    "\n",
    "        identity = C3\n",
    "        C4 = self.conv2(C3)\n",
    "        C4 = self.bn2(C4)\n",
    "        C4 = self.relu2(C4)\n",
    "        C5 = self.conv3(C4)\n",
    "        C5 = self.bn3(C5)\n",
    "        C5 = self.relu3(C5 + identity)\n",
    "\n",
    "        # ResNet Block-2\n",
    "        identity = C5\n",
    "        C6 = self.conv2(C5)\n",
    "        C6 = self.bn2(C6)\n",
    "        C6 = self.relu2(C6)\n",
    "        C7 = self.conv3(C6)\n",
    "        C7 = self.bn3(C7)\n",
    "        C7 = self.relu3(C7 + self.downsample1(identity))\n",
    "\n",
    "        identity = C7\n",
    "        C8 = self.conv2(C7)\n",
    "        C8 = self.bn2(C8)\n",
    "        C8 = self.relu2(C8)\n",
    "        C9 = self.conv3(C8)\n",
    "        C9 = self.bn3(C9)\n",
    "        C9 = self.relu3(C9 + identity)\n",
    "\n",
    "        # ResNet Block-3\n",
    "        identity = C9\n",
    "        C10 = self.conv2(C9)\n",
    "        C10 = self.bn2(C10)\n",
    "        C10 = self.relu2(C10)\n",
    "        C11 = self.conv3(C10)\n",
    "        C11 = self.bn3(C11)\n",
    "        C11 = self.relu3(C11 + self.downsample2(identity))\n",
    "\n",
    "        identity = C11\n",
    "        C12 = self.conv2(C11)\n",
    "        C12 = self.bn2(C12)\n",
    "        C12 = self.relu2(C12)\n",
    "        C13 = self.conv3(C12)\n",
    "        C13 = self.bn3(C13)\n",
    "        C13 = self.relu3(C13 + identity)\n",
    "\n",
    "        # ResNet Block-4\n",
    "        identity = C13\n",
    "        C14 = self.conv2(C3)\n",
    "        C14 = self.bn2(C14)\n",
    "        C14 = self.relu2(C14)\n",
    "        C15 = self.conv3(C14)\n",
    "        C15 = self.bn3(C15)\n",
    "        C15 = self.relu3(C15 + self.downsample2(identity))\n",
    "\n",
    "        identity = C15\n",
    "        C16 = self.conv2(C15)\n",
    "        C16 = self.bn2(C16)\n",
    "        C16 = self.relu2(C16)\n",
    "        C17 = self.conv3(C16)\n",
    "        C17 = self.bn3(C17)\n",
    "        C17 = self.relu3(C17 + identity)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "model = Backbone()\n",
    "#model.load_state_dict(torch.load('resnet18.pth'), strict=False)\n",
    "# print(model) # 打印模型的网络结构\n",
    "pre = torch.load('resnet18.pth') # 下载地址：https://download.pytorch.org/models/resnet18-5c106cde.pth\n",
    "pre = [k for k, v in pre.items()]\n",
    "# print(pre)\n",
    "#model.state_dict().keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有layer和block这种层级关系\n",
    "为了能用上PyTorch提供的Pre-Training参数，所以还是得设计出跟官方一样的层级关系和命名方式，值得注意的是，这并不会影响你对网络结构进行调整。当然，前提是层级关系和命名保持不变，具体可以参考这篇文章：[pytorch修改网络结构后如何加装预训练模型](https://blog.csdn.net/qq_36414085/article/details/112652317)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['conv1.bias'], unexpected_keys=['fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, conv1_in, conv1_out, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(conv1_in, conv1_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv1_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(conv1_out)\n",
    "        \n",
    "        # downsample是增加x通道数用的，因为下面一层的F(x)可能会增加通道数，前面一层无法直接相加\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # 上一层的信息\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out) # conv-1有ReLU\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out) # 注意到这里conv-2没有ReLU\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # 没记错的李沐课里说的是用1x1卷积来增加通道数\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out) # 注意到，联合上一层信息之后在进行ReLU\n",
    "        return out\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "\n",
    "        # ResNet's Head\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet Block-1\n",
    "        self.layer1 = nn.Sequential(BasicBlock(64, 64), \n",
    "                                    BasicBlock(64, 64))\n",
    "\n",
    "        # ResNet Block-2 \n",
    "        downsample = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer2 = nn.Sequential(BasicBlock(64, 128, 2, downsample=downsample), \n",
    "                                    BasicBlock(128, 128))\n",
    "\n",
    "        # ResNet Block-3\n",
    "        downsample = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(256))\n",
    "        self.layer3 = nn.Sequential(BasicBlock(128, 256, 2, downsample=downsample), \n",
    "                                    BasicBlock(256, 256))\n",
    "\n",
    "        # ResNet Block-4\n",
    "        downsample = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(512))\n",
    "        self.layer4 = nn.Sequential(BasicBlock(256, 512, 2, downsample=downsample), \n",
    "                                    BasicBlock(512, 512))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        C_1 = self.conv1(x)\n",
    "        C_1 = self.bn1(C_1)\n",
    "        C_1 = self.relu(C_1)\n",
    "        C_1 = self.maxpool(C_1)\n",
    "\n",
    "        C_2 = self.layer1(C_1)\n",
    "        C_3 = self.layer2(C_2)\n",
    "        C_4 = self.layer3(C_3)\n",
    "        C_5 = self.layer4(C_4)\n",
    "\n",
    "        return C_5\n",
    "\n",
    "\n",
    "\n",
    "model = Backbone()\n",
    "#model.load_state_dict(torch.load('resnet18.pth'), strict=False)\n",
    "# print(model) # 打印模型的网络结构\n",
    "pre = torch.load('resnet18.pth') # 下载地址：https://download.pytorch.org/models/resnet18-5c106cde.pth\n",
    "pre = [k for k, v in pre.items()]\n",
    "# print(pre)\n",
    "model.state_dict().keys()\n",
    "model.load_state_dict(torch.load('resnet18.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55159b417f3826aea464d5c5c2f08c53809ba760ead055a010d5c73ccf6f5953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
