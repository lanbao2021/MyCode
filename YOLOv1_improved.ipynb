{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改进的YOLO v1\n",
    "\n",
    "backbone: ResNet_18\n",
    "\n",
    "neck: SPP\n",
    "\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone: ResNet_18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, conv1_in, conv1_out, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(conv1_in, conv1_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv1_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(conv1_out)\n",
    "        \n",
    "        # downsample是增加x通道数用的，因为下面一层的F(x)可能会增加通道数，前面一层无法直接相加\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # 上一层的信息\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out) # conv-1有ReLU\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out) # 注意到这里conv-2没有ReLU\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # 没记错的李沐课里说的是用1x1卷积来增加通道数\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out) # 注意到，联合上一层信息之后在进行ReLU\n",
    "        return out\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "\n",
    "        # ResNet's Head\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet Block-1\n",
    "        self.layer1 = nn.Sequential(BasicBlock(64, 64), \n",
    "                                    BasicBlock(64, 64))\n",
    "\n",
    "        # ResNet Block-2 \n",
    "        downsample = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer2 = nn.Sequential(BasicBlock(64, 128, 2, downsample=downsample), \n",
    "                                    BasicBlock(128, 128))\n",
    "\n",
    "        # ResNet Block-3\n",
    "        downsample = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(256))\n",
    "        self.layer3 = nn.Sequential(BasicBlock(128, 256, 2, downsample=downsample), \n",
    "                                    BasicBlock(256, 256))\n",
    "\n",
    "        # ResNet Block-4\n",
    "        downsample = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(512))\n",
    "        self.layer4 = nn.Sequential(BasicBlock(256, 512, 2, downsample=downsample), \n",
    "                                    BasicBlock(512, 512))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        C_1 = self.conv1(x)\n",
    "        C_1 = self.bn1(C_1)\n",
    "        C_1 = self.relu(C_1)\n",
    "        C_1 = self.maxpool(C_1)\n",
    "\n",
    "        C_2 = self.layer1(C_1)\n",
    "        C_3 = self.layer2(C_2)\n",
    "        C_4 = self.layer3(C_3)\n",
    "        C_5 = self.layer4(C_4)\n",
    "\n",
    "        return C_5\n",
    "\n",
    "\n",
    "\n",
    "# model = Backbone()\n",
    "# #model.load_state_dict(torch.load('resnet18.pth'), strict=False)\n",
    "# # print(model) # 打印模型的网络结构\n",
    "# pre = torch.load('resnet18.pth') # 下载地址：https://download.pytorch.org/models/resnet18-5c106cde.pth\n",
    "# pre = [k for k, v in pre.items()]\n",
    "# # print(pre)\n",
    "# model.state_dict().keys()\n",
    "# model.load_state_dict(torch.load('resnet18.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neck: SPP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Neck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 注：max_pool并没有可以学习的参数\n",
    "        # backbone ouput size: 13*13*512\n",
    "        # output size: (13-5+2*2)/1 + 1 = 13, channel=512\n",
    "        x_1 = torch.nn.functional.max_pool2d(x, 5, stride=1, padding=2)\n",
    "        # output size: (13-9+2*4)/1 + 1 = 13, channel=512\n",
    "        x_2 = torch.nn.functional.max_pool2d(x, 9, stride=1, padding=4)\n",
    "        # output size: (13-13+2*6)/1 + 1 = 13, channel=512\n",
    "        x_3 = torch.nn.functional.max_pool2d(x, 13, stride=1, padding=6)\n",
    "        # output size: 13*13, channel=512+512+512+512=2048\n",
    "        x = torch.cat([x, x_1, x_2, x_3], dim=1) \n",
    "\n",
    "        # SPP -> Detection Head还需要用1*1卷积降维到512个Channel\n",
    "        spp_to_head = nn.Sequential(nn.Conv2d(2048, 512, 1),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        return spp_to_head(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Head\n",
    "class Head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Head, self).__init__()\n",
    "        # SPP output size: 13*13*512\n",
    "        # size: 13*13, channel: 256\n",
    "        head1 = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # size: (13-3+2*1)/1 + 1 = 13, channel: 512\n",
    "        head2 = nn.Sequential(nn.Conv2d(256, 512, 3, stride=1, padding=1),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # size: 13*13, channel: 256\n",
    "        head3 = nn.Sequential(nn.Conv2d(512, 256, 1, stride=1),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "\n",
    "        # size: (13-3+2*1)/1 + 1 = 13, channel: 512\n",
    "        head4 = nn.Sequential(nn.Conv2d(256, 512, 3, stride=1, padding=1),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        pred = nn.Conv2d(512, 1 + 20 + 4, 1) # output [1, 25, 13, 13]\n",
    "\n",
    "        self.head = nn.Sequential(head1, head2, head3, head4, pred)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 Model\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv1, self).__init__()\n",
    "\n",
    "        self.backbone = Backbone()\n",
    "        self.neck = Neck()\n",
    "        self.head = Head()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.backbone(x)\n",
    "        out = self.neck(out)\n",
    "        out = self.head(out) \n",
    "\n",
    "        return out\n",
    "\n",
    "model = YOLOv1()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import torch.utils.data as data\n",
    "import xml.etree.ElementTree as ET # 读取XML文件需要导入的模块（Python 3.X）\n",
    "import cv2\n",
    "import Augmentations\n",
    "import numpy as np\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.path_train_txt = '/Users/lan/Downloads/VOCdevkit/VOC2007/ImageSets/Main/train.txt'\n",
    "        self.path_train_images = '/Users/lan/Downloads/VOCdevkit/VOC2007/JPEGImages/%s.jpg'\n",
    "        self.path_train_annotations = '/Users/lan/Downloads/VOCdevkit/VOC2007/Annotations/%s.xml'\n",
    "        self.index_images = [] # ['index_1', 'index_2', ...]\n",
    "        for line in open(self.path_train_txt):\n",
    "            self.index_images.append(line.strip())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" return (image, ground_truth) \"\"\"\n",
    "\n",
    "        self.image_index = self.index_images[index]\n",
    "        self.ground_truth_xml = ET.parse(self.path_train_annotations % self.image_index).getroot()\n",
    "        self.image = cv2.imread(self.path_train_images % self.image_index)\n",
    "        height, width, channels = self.image.shape\n",
    "\n",
    "        # xml标注文件中每个Object都有其class和[xmin, ymin, xmax, ymax]数据，我们需要读取出来\n",
    "        VOC_CLASSES_NAME = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                            'cow', 'diningtable', 'dog', 'horse',\n",
    "                            'motorbike', 'person', 'pottedplant',\n",
    "                            'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "        self.class_name_to_index = dict(zip(VOC_CLASSES_NAME, range(len(VOC_CLASSES_NAME))))\n",
    "        self.xmin, self.ymin, self.xmax, self.ymax, self.index_class_name = 0, 0, 0, 0, 0\n",
    "        self.ground_truth = []\n",
    "\n",
    "        # 从xml标注文件中读取[[xmin, ymin, xmax, ymax, index_class_name], ... ]\n",
    "        for item in self.ground_truth_xml.iter('object'):\n",
    "            \n",
    "            class_name = item.find('name').text.lower().strip()\n",
    "            self.index_class_name = self.class_name_to_index[class_name]\n",
    "\n",
    "            bounding_box = item.find('bndbox')\n",
    "            # 因为图像会进行归一化，所以矩形框也要跟着变\n",
    "            # -1是因为xml文件中的坐标是从1开始的，而图像坐标是从左上角的0开始\n",
    "            self.xmin = (int(bounding_box.find('xmin').text) - 1) / width # 要不要float我还不确定\n",
    "            self.ymin = (int(bounding_box.find('ymin').text) - 1) / height\n",
    "            self.xmax = (int(bounding_box.find('xmax').text) - 1) / width\n",
    "            self.ymax = (int(bounding_box.find('ymax').text) - 1) / height\n",
    "\n",
    "            # [[xmin, ymin, xmax, ymax, index_class_name], ... ]\n",
    "            self.ground_truth.append([self.xmin, self.ymin, self.xmax, self.ymax, self.index_class_name])\n",
    "        \n",
    "        # 对图像做数据增强\n",
    "        if len(self.ground_truth) == 0:\n",
    "            self.ground_truth = np.zeros([1, 5]) # 确定是否有目标\n",
    "        else:\n",
    "            self.ground_truth = np.array(self.ground_truth) # 有的话转成np.array数组\n",
    "        \n",
    "        transform = Augmentations.SSDAugmentation(416) # 训练数据的大小416*416，可选择输入640\n",
    "        self.image, self.bounding_box, self.index_class_name = transform(self.image, \n",
    "                                                                         self.ground_truth[:, :4],\n",
    "                                                                         self.ground_truth[:, 4])\n",
    "        \n",
    "        # cv.imread-> BGR -> RGB，与img[:,:,::-1]是等价的\n",
    "        self.image = self.image[:, :, (2, 1, 0)]                                                                            \n",
    "        \n",
    "        # bounding_box: (1,4), index_class_name:(1,) \n",
    "        # np.expand_dims(index_class_name, axis=1):(1,1)\n",
    "        # np.hstack后得到(1,5)\n",
    "        self.ground_truth = np.hstack((self.bounding_box, np.expand_dims(self.index_class_name, axis=1)))\n",
    "        \n",
    "        # permute(2, 0, 1)把通道数放到前面去(W,H,C)->(C,W,H)，相当于img = img.transpose(2, 0, 1)\n",
    "        self.image = torch.from_numpy(self.image).permute(2, 0, 1)\n",
    "\n",
    "        \n",
    "\n",
    "        return self.image, self.ground_truth, height, width \n",
    "        # 注意此时self.ground_truth是一个np.array对象，标签也变成了float\n",
    "        # 举例验证的代码\n",
    "        # data = Dataset()\n",
    "        # a = data.__getitem__(1)\n",
    "        # data.ground_truth\n",
    "        # array([[ 0.43127962,  0.20664207,  0.65402844,  0.71217712, 14.        ],\n",
    "        #        [ 0.13744076,  0.26568266,  0.87914692,  1.        , 12.        ]])\n",
    "\n",
    "\n",
    "def collate_fn(data_batch):\n",
    "    # 这个data_batch是什么呢？[dataset[0],dataset[1],...,dataset[batch_size-1]]\n",
    "    # dataset[0]其实就是调用了__getitem__()方法取出一个img和一个target，组成的一个tuple\n",
    "    # sample[0]对应img，sample[1]对应target或者说label，ground truth\n",
    "    ground_truth = []\n",
    "    images = []\n",
    "    for item in data_batch:\n",
    "        images.append(item[0])\n",
    "        ground_truth.append(torch.FloatTensor(item[1]))\n",
    "    \n",
    "    # torch.stack(images, 0)就是实现(batch_size, H, W)\n",
    "    return torch.stack(images, 0), ground_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 测试dataloader能否正常使用\n",
    "data = Dataset()\n",
    "dataloader = torch.utils.data.DataLoader(data,\n",
    "                                         batch_size=1, \n",
    "                                         shuffle=True, \n",
    "                                         collate_fn=collate_fn,\n",
    "                                         #num_workers=2, # 该参数去掉能正常使用\n",
    "                                         pin_memory=True)\n",
    "i=0\n",
    "for iter_i, (images, ground_truth) in enumerate(dataloader):\n",
    "    print(images.shape)\n",
    "    print(len(ground_truth))\n",
    "    if i==0:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 13, 13])\n",
      "torch.Size([1, 512, 13, 13])\n",
      "torch.Size([1, 25, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# 测试模型的输出是否正确\n",
    "data = Dataset()\n",
    "a = data.__getitem__(1)\n",
    "data.ground_truth\n",
    "img = a[0]\n",
    "img = torch.unsqueeze(img, dim=0)\n",
    "img.shape\n",
    "model(img).shape\n",
    "img = model.backbone(img)\n",
    "print(img.shape)\n",
    "img = model.neck(img)\n",
    "print(img.shape)\n",
    "img = model.head(img)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55159b417f3826aea464d5c5c2f08c53809ba760ead055a010d5c73ccf6f5953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
