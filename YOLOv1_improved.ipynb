{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改进的YOLO v1\n",
    "\n",
    "backbone: ResNet_18\n",
    "\n",
    "neck: SPP\n",
    "\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone: ResNet_18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, conv1_in, conv1_out, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(conv1_in, conv1_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv1_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(conv1_out)\n",
    "        \n",
    "        # downsample是增加x通道数用的，因为下面一层的F(x)可能会增加通道数，前面一层无法直接相加\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # 上一层的信息\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out) # conv-1有ReLU\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out) # 注意到这里conv-2没有ReLU\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x) # 没记错的李沐课里说的是用1x1卷积来增加通道数\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out) # 注意到，联合上一层信息之后在进行ReLU\n",
    "        return out\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "\n",
    "        # ResNet's Head\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet Block-1\n",
    "        self.layer1 = nn.Sequential(BasicBlock(64, 64), \n",
    "                                    BasicBlock(64, 64))\n",
    "\n",
    "        # ResNet Block-2 \n",
    "        downsample = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer2 = nn.Sequential(BasicBlock(64, 128, 2, downsample=downsample), \n",
    "                                    BasicBlock(128, 128))\n",
    "\n",
    "        # ResNet Block-3\n",
    "        downsample = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(256))\n",
    "        self.layer3 = nn.Sequential(BasicBlock(128, 256, 2, downsample=downsample), \n",
    "                                    BasicBlock(256, 256))\n",
    "\n",
    "        # ResNet Block-4\n",
    "        downsample = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "                                   nn.BatchNorm2d(512))\n",
    "        self.layer4 = nn.Sequential(BasicBlock(256, 512, 2, downsample=downsample), \n",
    "                                    BasicBlock(512, 512))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        C_1 = self.conv1(x)\n",
    "        C_1 = self.bn1(C_1)\n",
    "        C_1 = self.relu(C_1)\n",
    "        C_1 = self.maxpool(C_1)\n",
    "\n",
    "        C_2 = self.layer1(C_1)\n",
    "        C_3 = self.layer2(C_2)\n",
    "        C_4 = self.layer3(C_3)\n",
    "        C_5 = self.layer4(C_4)\n",
    "\n",
    "        return C_5\n",
    "\n",
    "\n",
    "\n",
    "# model = Backbone()\n",
    "# #model.load_state_dict(torch.load('resnet18.pth'), strict=False)\n",
    "# # print(model) # 打印模型的网络结构\n",
    "# pre = torch.load('resnet18.pth') # 下载地址：https://download.pytorch.org/models/resnet18-5c106cde.pth\n",
    "# pre = [k for k, v in pre.items()]\n",
    "# # print(pre)\n",
    "# model.state_dict().keys()\n",
    "# model.load_state_dict(torch.load('resnet18.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neck: SPP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Neck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # backbone ouput size: 13*13*512\n",
    "        # output size: (13-5+2*2)/1 + 1 = 13, channel=512\n",
    "        x_1 = torch.nn.functional.max_pool2d(x, 5, stride=1, padding=2)\n",
    "        # output size: (13-9+2*4)/1 + 1 = 13, channel=512\n",
    "        x_2 = torch.nn.functional.max_pool2d(x, 9, stride=1, padding=4)\n",
    "        # output size: (13-13+2*6)/1 + 1 = 13, channel=512\n",
    "        x_3 = torch.nn.functional.max_pool2d(x, 13, stride=1, padding=6)\n",
    "        # output size: 13*13, channel=512+512+512+512=2048\n",
    "        x = torch.cat([x, x_1, x_2, x_3], dim=1) \n",
    "\n",
    "        # SPP -> Detection Head还需要用1*1卷积降维到512个Channel\n",
    "        spp_to_head = nn.Sequential(nn.Conv2d(2048, 512, 1),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        return spp_to_head(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Head\n",
    "class Head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Head, self).__init__()\n",
    "        # SPP output size: 13*13*512\n",
    "        # size: 13*13, channel: 256\n",
    "        head1 = nn.Sequential(nn.Conv2d(512, 256, 1),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # size: (13-3+2*1)/1 + 1 = 13, channel: 512\n",
    "        head2 = nn.Sequential(nn.Conv2d(256, 512, 3),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # size: 13*13, channel: 256\n",
    "        head3 = nn.Sequential(nn.Conv2d(512, 256, 1),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "\n",
    "        # size: (13-3+2*1)/1 + 1 = 13, channel: 512\n",
    "        head4 = nn.Sequential(nn.Conv2d(256, 512, 3),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.head = nn.Sequential(head1, head2, head3, head4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 Model\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv1, self).__init__()\n",
    "\n",
    "        self.backbone = Backbone()\n",
    "        self.neck = Neck()\n",
    "        self.head = Head()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.backbone(x)\n",
    "        out = self.neck(out)\n",
    "        out = self.head(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = YOLOv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55159b417f3826aea464d5c5c2f08c53809ba760ead055a010d5c73ccf6f5953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
